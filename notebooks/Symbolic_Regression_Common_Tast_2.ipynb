{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXnXLwG0oN3u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1d50d4e-9ee1-495f-f029-bf18520d5669"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 12.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60 - Train Loss: 3.9520 - Val Loss: 2.7216\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 11.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/60 - Train Loss: 2.1771 - Val Loss: 2.1778\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 11.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/60 - Train Loss: 1.7553 - Val Loss: 1.9370\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 13.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/60 - Train Loss: 1.5909 - Val Loss: 1.7249\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 12.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/60 - Train Loss: 1.4084 - Val Loss: 1.5423\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 12.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/60 - Train Loss: 1.2783 - Val Loss: 1.4258\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 12.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/60 - Train Loss: 1.1367 - Val Loss: 1.3559\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 13.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/60 - Train Loss: 1.0903 - Val Loss: 1.2792\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 13.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/60 - Train Loss: 1.0389 - Val Loss: 1.2156\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 12.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/60 - Train Loss: 0.9910 - Val Loss: 1.1624\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 12.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/60 - Train Loss: 0.9506 - Val Loss: 1.1219\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 12.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/60 - Train Loss: 0.9378 - Val Loss: 1.0924\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 13.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/60 - Train Loss: 0.8539 - Val Loss: 1.0647\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 12.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/60 - Train Loss: 0.8334 - Val Loss: 1.0411\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 12.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/60 - Train Loss: 0.8301 - Val Loss: 1.0208\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 13.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/60 - Train Loss: 0.8286 - Val Loss: 1.0037\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 13.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/60 - Train Loss: 0.7526 - Val Loss: 0.9837\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 12.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/60 - Train Loss: 0.7517 - Val Loss: 0.9672\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 11.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/60 - Train Loss: 0.7390 - Val Loss: 0.9503\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 13.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/60 - Train Loss: 0.7202 - Val Loss: 0.9340\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 12.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21/60 - Train Loss: 0.7061 - Val Loss: 0.9213\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 12.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22/60 - Train Loss: 0.6643 - Val Loss: 0.9065\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 12.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23/60 - Train Loss: 0.6497 - Val Loss: 0.8938\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 12.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24/60 - Train Loss: 0.6620 - Val Loss: 0.8855\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 13.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25/60 - Train Loss: 0.6470 - Val Loss: 0.8769\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 12.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26/60 - Train Loss: 0.6320 - Val Loss: 0.8701\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 12.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27/60 - Train Loss: 0.6252 - Val Loss: 0.8620\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 12.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28/60 - Train Loss: 0.6138 - Val Loss: 0.8553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 13.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29/60 - Train Loss: 0.6074 - Val Loss: 0.8504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 12.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30/60 - Train Loss: 0.6095 - Val Loss: 0.8434\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 12.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31/60 - Train Loss: 0.5853 - Val Loss: 0.8358\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 12.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32/60 - Train Loss: 0.5936 - Val Loss: 0.8298\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 12.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33/60 - Train Loss: 0.5664 - Val Loss: 0.8227\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 12.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34/60 - Train Loss: 0.5532 - Val Loss: 0.8170\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 12.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35/60 - Train Loss: 0.5334 - Val Loss: 0.8122\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 12.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36/60 - Train Loss: 0.5223 - Val Loss: 0.8049\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 12.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37/60 - Train Loss: 0.5281 - Val Loss: 0.7991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00,  9.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38/60 - Train Loss: 0.5203 - Val Loss: 0.7964\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00,  9.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39/60 - Train Loss: 0.5144 - Val Loss: 0.7939\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00,  9.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40/60 - Train Loss: 0.5107 - Val Loss: 0.7872\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 10.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41/60 - Train Loss: 0.4818 - Val Loss: 0.7821\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00,  9.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42/60 - Train Loss: 0.4566 - Val Loss: 0.7817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00,  9.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43/60 - Train Loss: 0.4779 - Val Loss: 0.7780\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 12.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44/60 - Train Loss: 0.4794 - Val Loss: 0.7752\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 12.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45/60 - Train Loss: 0.4769 - Val Loss: 0.7744\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 12.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46/60 - Train Loss: 0.4605 - Val Loss: 0.7692\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 12.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 47/60 - Train Loss: 0.4432 - Val Loss: 0.7657\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 12.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 48/60 - Train Loss: 0.4324 - Val Loss: 0.7653\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 13.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49/60 - Train Loss: 0.4215 - Val Loss: 0.7673\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 13.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50/60 - Train Loss: 0.4059 - Val Loss: 0.7579\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 13.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 51/60 - Train Loss: 0.4142 - Val Loss: 0.7537\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 13.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 52/60 - Train Loss: 0.4089 - Val Loss: 0.7549\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 12.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 53/60 - Train Loss: 0.3833 - Val Loss: 0.7579\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 12.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 54/60 - Train Loss: 0.3920 - Val Loss: 0.7575\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 12.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 55/60 - Train Loss: 0.3872 - Val Loss: 0.7522\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 12.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 56/60 - Train Loss: 0.3784 - Val Loss: 0.7492\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 12.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 57/60 - Train Loss: 0.3568 - Val Loss: 0.7554\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 13.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 58/60 - Train Loss: 0.3681 - Val Loss: 0.7552\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 12.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 59/60 - Train Loss: 0.3631 - Val Loss: 0.7515\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 12.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 60/60 - Train Loss: 0.3559 - Val Loss: 0.7531\n",
            "Model saved at /mnt/data/transformer_model.pth\n",
            "Vocabulary saved at /mnt/data/vocab.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "import os\n",
        "\n",
        "# Load the tokenized dataset\n",
        "df = pd.read_csv(\"/content/tokenized_equations.csv\")\n",
        "\n",
        "# Ensure the 'tokens' column is present\n",
        "if \"tokens\" not in df.columns:\n",
        "    raise ValueError(\"The CSV file must contain a 'tokens' column with tokenized sequences.\")\n",
        "\n",
        "# Tokenize and build vocabulary\n",
        "tokenized_equations = [row.split(\" | \") for row in df[\"tokens\"].dropna()]\n",
        "all_tokens = [token for seq in tokenized_equations for token in seq]\n",
        "\n",
        "# Define special tokens\n",
        "special_tokens = [\"<PAD>\", \"<UNK>\", \"<EOS>\"]\n",
        "vocab = {token: idx for idx, token in enumerate(set(all_tokens) | set(special_tokens), start=0)}\n",
        "\n",
        "# Encode tokenized sequences into numerical format\n",
        "def encode_sequence(sequence, vocab):\n",
        "    return [vocab.get(token, vocab[\"<UNK>\"]) for token in sequence] + [vocab[\"<EOS>\"]]  # Append EOS\n",
        "\n",
        "encoded_sequences = [encode_sequence(seq, vocab) for seq in tokenized_equations]\n",
        "\n",
        "# Prepare input-output pairs for next-token prediction\n",
        "input_sequences = [seq[:-1] for seq in encoded_sequences]  # Remove last token\n",
        "output_sequences = [seq[1:] for seq in encoded_sequences]  # Shift left by 1 token\n",
        "\n",
        "# Padding sequences to the same length\n",
        "max_len = max(len(seq) for seq in input_sequences)\n",
        "def pad_sequence(seq, max_len, pad_token=0):\n",
        "    return seq + [pad_token] * (max_len - len(seq))\n",
        "\n",
        "input_sequences = [pad_sequence(seq, max_len) for seq in input_sequences]\n",
        "output_sequences = [pad_sequence(seq, max_len) for seq in output_sequences]\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "input_tensor = torch.tensor(input_sequences, dtype=torch.long)\n",
        "output_tensor = torch.tensor(output_sequences, dtype=torch.long)\n",
        "\n",
        "# Train-test split\n",
        "split_idx = int(0.8 * len(input_tensor))\n",
        "train_inputs, val_inputs = input_tensor[:split_idx], input_tensor[split_idx:]\n",
        "train_outputs, val_outputs = output_tensor[:split_idx], output_tensor[split_idx:]\n",
        "\n",
        "# PyTorch Dataset & DataLoader\n",
        "class EquationDataset(Dataset):\n",
        "    def __init__(self, inputs, outputs):\n",
        "        self.inputs = inputs\n",
        "        self.outputs = outputs\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.inputs[idx], self.outputs[idx]\n",
        "\n",
        "train_dataset = EquationDataset(train_inputs, train_outputs)\n",
        "val_dataset = EquationDataset(val_inputs, val_outputs)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Sinusoidal Positional Encoding\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, embed_dim, max_len=100):\n",
        "        super().__init__()\n",
        "        position = torch.arange(max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, embed_dim, 2) * (-math.log(10000.0) / embed_dim))\n",
        "        pe = torch.zeros(1, max_len, embed_dim)\n",
        "        pe[0, :, 0::2] = torch.sin(position * div_term)\n",
        "        pe[0, :, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.shape[1]]\n",
        "\n",
        "# Transformer Model\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim=128, num_heads=4, num_layers=3, hidden_dim=256):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.positional_encoding = PositionalEncoding(embed_dim, max_len)\n",
        "        encoder_layers = nn.TransformerEncoderLayer(embed_dim, num_heads, hidden_dim, batch_first=True)\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layers, num_layers)\n",
        "        self.fc = nn.Linear(embed_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = self.positional_encoding(x)\n",
        "        x = self.transformer(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Initialize model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = TransformerModel(vocab_size=len(vocab)).to(device)\n",
        "\n",
        "# Training Setup\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=vocab[\"<PAD>\"])  # Ignore padding in loss calculation\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0006)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.9)\n",
        "\n",
        "# Training Loop\n",
        "num_epochs = 60   # Increase epochs for better learning\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for inputs, targets in tqdm(train_loader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs).permute(0, 2, 1)  # Reshape for loss function\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in val_loader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs).permute(0, 2, 1)\n",
        "            loss = criterion(outputs, targets)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    scheduler.step()\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {total_loss/len(train_loader):.4f} - Val Loss: {val_loss/len(val_loader):.4f}\")\n",
        "\n",
        "# Save Model & Vocab\n",
        "os.makedirs(\"/mnt/data\", exist_ok=True)\n",
        "torch.save(model.state_dict(), \"/mnt/data/transformer_model.pth\")\n",
        "torch.save(vocab, \"/mnt/data/vocab.pkl\")\n",
        "print(\"Model saved at /mnt/data/transformer_model.pth\")\n",
        "print(\"Vocabulary saved at /mnt/data/vocab.pkl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# --- Load Model and Vocab ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load vocabulary\n",
        "vocab = torch.load(\"/mnt/data/vocab.pkl\")\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# Define Positional Encoding\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, embed_dim, max_len=100):\n",
        "        super().__init__()\n",
        "        position = torch.arange(max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, embed_dim, 2) * (-math.log(10000.0) / embed_dim))\n",
        "        pe = torch.zeros(1, max_len, embed_dim)\n",
        "        pe[0, :, 0::2] = torch.sin(position * div_term)\n",
        "        pe[0, :, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.shape[1]]\n",
        "\n",
        "# Define Transformer Model\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim=128, num_heads=4, num_layers=3, hidden_dim=256):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.positional_encoding = PositionalEncoding(embed_dim, max_len=46)  # Ensure correct max_len\n",
        "        self.transformer = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(embed_dim, num_heads, hidden_dim, batch_first=True),\n",
        "            num_layers\n",
        "        )\n",
        "        self.fc = nn.Linear(embed_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = self.positional_encoding(x)\n",
        "        x = self.transformer(x)\n",
        "        return self.fc(x)\n",
        "\n",
        "# Load Model\n",
        "model = TransformerModel(vocab_size).to(device)\n",
        "model.load_state_dict(torch.load(\"/mnt/data/transformer_model.pth\", map_location=device))\n",
        "model.eval()\n",
        "\n",
        "# --- Load Data ---\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)  # Ensure train_loader is defined\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# --- Define Loss Function ---\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=vocab[\"<PAD>\"])  # Ignore padding tokens\n",
        "\n",
        "# --- Evaluate Training Loss ---\n",
        "total_train_loss = 0\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, targets in train_loader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        outputs = model(inputs)  # (batch, seq_len, vocab_size)\n",
        "        loss = criterion(outputs.permute(0, 2, 1), targets)  # Reshape for loss calculation\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "avg_train_loss = total_train_loss / len(train_loader)\n",
        "\n",
        "# --- Evaluate Validation Loss & Accuracy ---\n",
        "total_val_loss, total_correct, total_tokens = 0, 0, 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, targets in val_loader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs.permute(0, 2, 1), targets)\n",
        "        total_val_loss += loss.item()\n",
        "\n",
        "        # Compute accuracy (ignoring PAD tokens)\n",
        "        predictions = torch.argmax(outputs, dim=-1)\n",
        "        mask = targets != vocab[\"<PAD>\"]\n",
        "        total_correct += (predictions == targets).masked_select(mask).sum().item()\n",
        "        total_tokens += mask.sum().item()\n",
        "\n",
        "avg_val_loss = total_val_loss / len(val_loader)\n",
        "accuracy = total_correct / total_tokens * 100\n",
        "\n",
        "# --- Print Evaluation Results ---\n",
        "print(f\"Training Loss: {avg_train_loss:.4f}\")\n",
        "print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
        "print(f\"Validation Accuracy: {accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McPsULZUELCd",
        "outputId": "dbc48620-9898-46d0-b433-19dc19d8ffbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.3006\n",
            "Validation Loss: 0.7531\n",
            "Validation Accuracy: 80.98%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-56-3a53dc8a35ad>:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  vocab = torch.load(\"/mnt/data/vocab.pkl\")\n",
            "<ipython-input-56-3a53dc8a35ad>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(\"/mnt/data/transformer_model.pth\", map_location=device))\n"
          ]
        }
      ]
    }
  ]
}